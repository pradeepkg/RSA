"use strict";(self.webpackChunkdocku=self.webpackChunkdocku||[]).push([[6615],{44416:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"attribute-sync","metadata":{"permalink":"/RSA/basics/attribute-sync","source":"@site/basics/attribute-sync/attribute-sync.mdx","title":"Attribute Synchronization","description":"Overview","date":"2024-10-25T00:00:00.000Z","tags":[{"inline":true,"label":"Attribute","permalink":"/RSA/basics/tags/attribute"},{"inline":true,"label":"Synchronization","permalink":"/RSA/basics/tags/synchronization"}],"readingTime":16.733333333333334,"hasTruncateMarker":true,"authors":[{"name":"Pradeep Kadambar","title":"Creator","url":"https://www.linkedin.com/in/pradeepkg/","imageURL":"https://github.com/pradeepkg.png","key":"pradeepkg","page":null}],"frontMatter":{"slug":"attribute-sync","title":"Attribute Synchronization","date":"2024-10-25T00:00:00.000Z","authors":"pradeepkg","tags":["Attribute","Synchronization"],"keywords":["Attribute","Synchronization"],"draft":false},"unlisted":false,"nextItem":{"title":"Adding Custom JDBC Driver","permalink":"/RSA/basics/custom-jdbc"}},"content":"## Overview\\r\\nAttribute synchronization is a process that ensures consistency between user identity data and account data across different systems. \\r\\n\\r\\n![img](img/attribute-sync.svg)\\r\\n\x3c!-- truncate --\x3e\\r\\n\\r\\nThis process is initiated when changes in user attribute values are detected after identity data collection and unification. When such changes occur, the system generates a change request to update the specified target account attributes, which are used to access business sources like applications and directories. Attribute synchronization process can target one or more downstream applications.\\r\\n\\r\\n*e.g. When a user\'s email attribute in an HR system is linked to the corresponding mail attribute in an Active Directory account, a mapping can be established to ensure that any updates to the user\'s email are automatically reflected in the Active Directory account. This process requires defining both the source and target attributes for each business source and determining the transformation method needed to update the target attribute accurately.*\\r\\n\\r\\nWhen a change is detected, G&L will generate a change request with change items for each account mapped to the user with the change and for each business source. \\r\\n\\r\\n*e.g. In the previous scenario, if a user\'s email address changes in the HR system and attribute synchronization has been mapped for both Active Directory and an Oracle database, a change request will be generated containing two change items: one for updating the email in Active Directory and another for updating it in the Oracle database.*\\r\\n\\r\\n:::note Notes\\r\\n- This is an optional feature that must be explicitly enabled before it can be configured.\\r\\n- Attribute synchronization is applicable only to accounts held by individual users and does not extend to shared accounts\\r\\n:::\\r\\n\\r\\nAfter understanding how attribute synchronization works, let\'s examine the high-level steps to configure it in your Governance and Lifecycle (G&L) environment.\\r\\n\\r\\n![img](img/attribute-sync-config.svg)\\r\\n\\r\\n## Configuration\\r\\n1. Go to **Admin > System** and click on **Settings** tab. Click ***Edit***.<br />![img](img/enable-attribute-sync.png)\\r\\n2. Ensure the Account Data Controller (ADC) for the application has the required attributes defined and properly mapped. <br /><br />![img](img/adc-collect.png)\\r\\n3. Go to **Collectors > Attribute Synchronization**, for each of the target application attribute map a source user attribute. <br />Example:  \\r\\n    - Click on **Email Address** in the __Source User Attribute__ table\\r\\n    - Click on **New**. \\r\\n    - Select the application and the account attribute and click **OK**. Optionally, define a transformation for the attribute before it is sent to the target.<br /><br />![img](img/define-mapping.png). \\r\\n4. Finally, ensure that the ***Update an Account*** verb for the mapped AFX connector has been defined and the attributes are properly mapped.<br /><br />![img](img/afx-mapping.png)\\r\\n\\r\\n## Limitations\\r\\n\\r\\n- Attribute synchronization relies on mapping user attributes to account attributes. Due to limitations on the availability of account attributes, there is a maximum of 20 string attributes, 5 date attributes, and 5 integer attributes that can be used for synchronization.\\r\\n- Transformations can be applied to individual attributes but cannot combine multiple attributes. For example, converting all _First Name_ values to lowercase is possible, but creating a _Display Name_ by combining first name and last name is not supported."},{"id":"custom-jdbc","metadata":{"permalink":"/RSA/basics/custom-jdbc","source":"@site/basics/custom-jdbc/jdbc.mdx","title":"Adding Custom JDBC Driver","description":"In this blog, we\'ll explore the process of adding support for additional database drivers in Governance and Lifecycle (G&L) version 8.0 and above. By default, G&L is shipped only with drivers for Oracle and Microsoft SQL databases.","date":"2024-05-23T00:00:00.000Z","tags":[{"inline":true,"label":"Provisioning","permalink":"/RSA/basics/tags/provisioning"},{"inline":true,"label":"AFX","permalink":"/RSA/basics/tags/afx"},{"inline":true,"label":"JDBC","permalink":"/RSA/basics/tags/jdbc"},{"inline":true,"label":"Database","permalink":"/RSA/basics/tags/database"},{"inline":true,"label":"Driver","permalink":"/RSA/basics/tags/driver"}],"readingTime":6,"hasTruncateMarker":true,"authors":[{"name":"Pradeep Kadambar","title":"Creator","url":"https://www.linkedin.com/in/pradeepkg/","imageURL":"https://github.com/pradeepkg.png","key":"pradeepkg","page":null}],"frontMatter":{"slug":"custom-jdbc","title":"Adding Custom JDBC Driver","date":"2024-05-23T00:00:00.000Z","authors":"pradeepkg","tags":["Provisioning","AFX","JDBC","Database","Driver"],"keywords":["Provisioning","AFX","JDBC","Database","Driver"],"draft":false},"unlisted":false,"prevItem":{"title":"Attribute Synchronization","permalink":"/RSA/basics/attribute-sync"},"nextItem":{"title":"Manipulating Accounts","permalink":"/RSA/basics/data-processors-adc"}},"content":"In this blog, we\'ll explore the process of adding support for additional database drivers in Governance and Lifecycle (G&L) version 8.0 and above. By default, G&L is shipped only with drivers for Oracle and Microsoft SQL databases.\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\nStarting with G&L 8.0, all the individual JDBC connectors have been consolidated into a single generic database connector. This generic connector natively supports the following databases:\\r\\n- DB2\\r\\n- Oracle\\r\\n- Sybase\\r\\n- SQLServer\\r\\n- jTDS\\r\\n- MySQL\\r\\n- ODBC compliant databases\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\n\\r\\n**Steps**\\r\\n1. Login to G&L console as system administrator.\\r\\n2. If you are creating a new connector proceed to step 4.\\r\\n3. For existing connector, click **Test Connector Settings** which should throw a driver class load error.<br /><br />![img](img/1.png)\\r\\n4. Go to **AFX > Connector Templates** and click on ***Generic Database***.<br /><br />![img](img/2.png)\\r\\n5. Under **File Content** tab, click on **Upload Jar**.<br /><br />![img](img/3.png)\\r\\n6. Select the JDBC driver jar file and click **OK**.\\r\\n7. Go to the connector and edit the driver class and connector string as needed.<br />![img](img/4.png)\\r\\n8. Click ***Test Connector Settings***."},{"id":"data-processors-adc","metadata":{"permalink":"/RSA/basics/data-processors-adc","source":"@site/basics/data-processors/data-processors-adc/data-processors-adc.mdx","title":"Manipulating Accounts","description":"In this blog post, I will guide you through the effective utilization of data processors during account collections to address common use cases. If you are not familiar with data processors, I recommend reading the Data Processors Basics before proceeding, as it will provide a foundational understanding of the concepts discussed in this blog.","date":"2024-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"Data Processors","permalink":"/RSA/basics/tags/data-processors"},{"inline":true,"label":"ADC","permalink":"/RSA/basics/tags/adc"},{"inline":true,"label":"Account","permalink":"/RSA/basics/tags/account"},{"inline":true,"label":"Group","permalink":"/RSA/basics/tags/group"}],"readingTime":35.86666666666667,"hasTruncateMarker":true,"authors":[{"name":"Pradeep Kadambar","title":"Creator","url":"https://www.linkedin.com/in/pradeepkg/","imageURL":"https://github.com/pradeepkg.png","key":"pradeepkg","page":null}],"frontMatter":{"slug":"data-processors-adc","title":"Manipulating Accounts","date":"2024-02-01T00:00:00.000Z","authors":"pradeepkg","tags":["Data Processors","ADC","Account","Group"],"keywords":["Data Processors","ADC","Account","Group"]},"unlisted":false,"prevItem":{"title":"Adding Custom JDBC Driver","permalink":"/RSA/basics/custom-jdbc"},"nextItem":{"title":"Manipulating Identities","permalink":"/RSA/basics/data-processors-idc"}},"content":"In this blog post, I will guide you through the effective utilization of data processors during account collections to address common use cases. If you are not familiar with data processors, I recommend reading the **[Data Processors Basics](data-processors-basics)** before proceeding, as it will provide a foundational understanding of the concepts discussed in this blog.\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\n### Manipulating Account Resolution Attribute\\r\\n\\r\\nIn the scenario where admin accounts collected from Active Directory ADC are identified as orphans, with _sAMAccountName_ formats differing from regular user accounts, we can resolve this by employing the _Pre_ADC_Handler_. This handler allows us to manipulate the raw data collected from the application and convert it to the desired format.\\r\\n\\r\\nTo implement this solution, follow the steps below:\\r\\n\\r\\n1. Log in to the console as a System Administrator.\\r\\n2. Navigate to **Collectors > Account Collectors** and select the account collector for the application in question.\\r\\n3. Click on **Edit**\\r\\n4. Choose the _Pre Custom Processing_ option.\\r\\n5. Navigate through the subsequent screens by clicking **Next** until you reach the _Pre-Processing Custom Script Details_ screen.\\r\\n6. Add the following SQL block below the comment \\"Custom Code Goes Here\\".\\r\\n\\r\\n```sql showLineNumbers\\r\\nFOR AllAccounts IN (\\r\\n  SELECT\\r\\n    LTRIM(amap.account_name, \'x\') as name\\r\\n  FROM\\r\\n    T_DC_SOURCEDATA_ACCOUNT_MAP amap\\r\\n    INNER JOIN T_DATA_COLLECTORS coll ON amap.dc_id = coll.id\\r\\n  WHERE\\r\\n    coll.id = v_dc_id\\r\\n    and amap.run_id = v_run_id\\r\\n) LOOP\\r\\nUPDATE\\r\\n  T_DC_SOURCEDATA_ACCOUNT_MAP AMAP\\r\\nSET\\r\\n  AMAP.USER_NAME = AllAccounts.name\\r\\nWHERE\\r\\n  AMAP.account_name = AllAccounts.name COMMIT;\\r\\nEND LOOP;\\r\\n```\\r\\n\\r\\nIn this SQL block, we are removing the \'**x**\' prefix from the Active Directory _sAMAccountName_, assuming it is stored in the user identity for mapping purposes.\\r\\n\\r\\nBy implementing this manipulation in the _Pre_ADC_Handler_, we ensure that the _sAMAccountName_ is appropriately modified before the unification process, allowing for accurate mapping of admin accounts to user identities.\\r\\n\\r\\n7. Click **Validate** to check for syntactical errors.\\r\\n8. Click **Finish**\\r\\n\\r\\n### Converting Account Status Format\\r\\n\\r\\nFor an application returning user account active status as true or false, but requiring conversion to an Account Disabled flag in the format of 1 and 0, we can achieve this by utilizing the Post_Account_Data_Load_Handler. This handler allows us to manipulate the data collected from the application and convert it to the desired format.\\r\\n\\r\\nFollow these steps to implement the solution:\\r\\n\\r\\n1. Log in to the console as a System Administrator.\\r\\n2. Navigate to **Collectors > Account Collectors** and select the account collector associated with the application.\\r\\n3. Click on **Edit.**\\r\\n4. Choose the _Post Custom Processing_ option.\\r\\n5. Navigate through the subsequent screens by clicking **Next** until you reach the _Post-Processing Custom Script Details_ screen.\\r\\n6. Add the following SQL block below the comment \\"Custom Code Goes Here\\".\\r\\n\\r\\n```sql showLineNumbers\\r\\nFOR DisabledAccounts IN (\\r\\n  SELECT\\r\\n    account.name,\\r\\n    CASE account.cas20 WHEN \'true\' THEN \'0\' ELSE \'1\' END as isDisabled\\r\\n  FROM\\r\\n    T_AV_ACCOUNTS account\\r\\n    INNER JOIN T_DATA_COLLECTORS collector ON account.adc_id = collector.id\\r\\n  WHERE\\r\\n    collector.id= v_dc_id\\r\\n) LOOP\\r\\nUPDATE\\r\\n  T_AV_ACCOUNTS A\\r\\nSET\\r\\n  A.IS_DISABLED = DisabledAccounts.isDisabled\\r\\nWHERE\\r\\n  A.name = DisabledAccounts.name\\r\\n  AND A.ADC_ID = v_dc_id\\r\\nCOMMIT;\\r\\nEND LOOP;\\r\\n```\\r\\n\\r\\nIn this SQL block, we are setting the Account Disabled flag by inverting the active status flag.\\r\\n\\r\\nBy implementing this conversion in the _Post_Account_Data_Load_Handler_, we ensure that the data is processed after it is loaded from the application, and the account status is represented in the desired format. This solution provides a tailored approach to meet the specific requirements of your application\'s account status representation.\\r\\n\\r\\n7. Click **Validate** to check for syntactical errors.\\r\\n8. Click **Finish**\\r\\n\\r\\n### Updating IS_DISABLED Flag for an Account using Global Variables:\\r\\n\\r\\nTo convert data obtained from a REST endpoint to the required 1 or 0 format for the IS_DISABLED field of the accounts and set the value of the IS_DISABLED field, follow these steps:\\r\\n\\r\\n1. Log in to the console as a System Administrator.\\r\\n2. Navigate to **Admin > System** and click on the **Global Variables** tab.\\r\\n3. Add the following configurable setting and save:\\r\\n   - **Variable Name**: processor_collector_enabled_values\\r\\n   - **Value: \'ACTIVE\',\'YES\',\'TRUE\',\'1\'**\\r\\n4. This solution utilizes configurable settings, specifically the **_processor_collector_enabled_values_** variable, to define enabled data fields that may be received through data collectors. Adjust the values in this variable to match the enabled flags for the accounts obtained from the REST endpoint.\\r\\n5. Navigate to **Collectors > Account Collectors** and select the account collector for the application.\\r\\n6. Click on **Edit**\\r\\n7. Choose the _Pre Custom Processing_ option.\\r\\n8. Navigate through the subsequent screens by clicking **Next** until you reach the **Pre-Processing Custom Script Details** screen.\\r\\n9. Add the following code snippet, adjusting the value of `CAS5` to the appropriate data column that contains the enabled flag for the account being collected:\\r\\n\\r\\n```sql showLineNumbers\\r\\nDECLARE\\r\\n   -- The run id and collector id will be substituted for variables v_run_id and v_dc_id during processing time.\\r\\n   v_run_id   NUMBER := :1;\\r\\n   v_dc_id    NUMBER := :2;\\r\\n\\r\\n   /*----------------------------------------------------------------------------------------------*/\\r\\n   /* Custom Variables */\\r\\n   /*----------------------------------------------------------------------------------------------*/\\r\\n   -- Standard Set of variables\\r\\n   v_proc_name       T_AV_JOB_STATS.Proc_Name%TYPE := \'ADC_Transformer\';\\r\\n   -- Procedure Specific variables\\r\\n   v_custom_message  VARCHAR2(2000) := \'ADC Transformer\';\\r\\n   v_log_message     VARCHAR2(2000);\\r\\n   v_is_disabled     NUMBER;\\r\\n   v_enabled_values  VARCHAR2(2000);\\r\\nBEGIN\\r\\n   /*----------------------------------------------------------------------------------------------*/\\r\\n   /* Custom Code - Start */\\r\\n   /*----------------------------------------------------------------------------------------------*/\\r\\n   -- begin message\\r\\n   UNFC_Processor_Log.INFO_BEGIN(v_run_id, v_proc_name, v_custom_message);\\r\\n\\r\\n   -- Fetch the list of enabled values from the AVUSER.T_AV_GLOBAL_VARIABLES table\\r\\n   -- \'ACTIVE\',\'YES\',\'TRUE\',\'1\'\\r\\n   SELECT UPPER(value) INTO v_enabled_values\\r\\n   FROM AVUSER.T_AV_GLOBAL_VARIABLES\\r\\n   WHERE parameter = \'processor_collector_enabled_values\';\\r\\n\\r\\n   -- Log the enabled values\\r\\n   v_log_message := \'Enabled Values: \' || v_enabled_values;\\r\\n   UNFC_Processor_Log.INFO_INFO(v_run_id, v_proc_name, v_log_message);\\r\\n\\r\\n   FOR AllAccounts IN (SELECT name, cas5 AS status\\r\\n      FROM T_DC_SOURCEDATA_ACCOUNT WHERE dc_id = v_dc_id AND run_id=v_run_id )\\r\\n   LOOP\\r\\n      -- Store the result of the CASE expression in v_is_disabled\\r\\n      v_is_disabled := 1; -- Assume disabled by default\\r\\n\\r\\n      -- Convert the enabled values into a table using XMLTABLE\\r\\n      FOR enabled_value IN (SELECT TRIM(COLUMN_VALUE) AS enabled_value FROM XMLTABLE(v_enabled_values))\\r\\n      LOOP\\r\\n         IF UPPER(AllAccounts.status) = enabled_value.enabled_value THEN\\r\\n            v_is_disabled := 0; -- Enable if the status matches any enabled value\\r\\n            EXIT; -- Exit the loop after finding a match\\r\\n         END IF;\\r\\n      END LOOP;\\r\\n\\r\\n      -- Update the custom account attribute IS_DISABLED that holds the account disabled status\\r\\n      -- Need to update at least one collected attribute if the change has to be persisted.\\r\\n      UPDATE T_DC_SOURCEDATA_ACCOUNT SET IS_DISABLED = v_is_disabled,\\r\\n\\t\\tCAS5 = AllAccounts.status || \' : \' || v_run_id\\r\\n      WHERE name = AllAccounts.name AND  run_id=v_run_id;\\r\\n\\r\\n      COMMIT;\\r\\n\\r\\n      -- Construct the log message\\r\\n      v_log_message := \'Account: \' || AllAccounts.name || \', Status: \' \\r\\n        || AllAccounts.status || \', IS_DISABLED: \' || v_is_disabled;\\r\\n\\r\\n      -- Print the log message using UNFC_Processor_Log.INFO_INFO\\r\\n      UNFC_Processor_Log.INFO_INFO(v_run_id, v_proc_name, v_log_message);\\r\\n   END LOOP;\\r\\n\\r\\n   -- end message\\r\\n   UNFC_Processor_Log.INFO_END(v_run_id, v_proc_name, v_custom_message);\\r\\n   /*----------------------------------------------------------------------------------------------*/\\r\\n   /* Custom Code - End */\\r\\n   /*----------------------------------------------------------------------------------------------*/\\r\\nEND;\\r\\n```\\r\\n\\r\\n9. Click **Validate** to check for syntactical errors.\\r\\n10. Click **Finish**\\r\\n11. Run the collectors and validate."},{"id":"data-processors-idc","metadata":{"permalink":"/RSA/basics/data-processors-idc","source":"@site/basics/data-processors/data-processors-idc/data-processors-idc.mdx","title":"Manipulating Identities","description":"In this blog post, I will guide you through the effective utilization of pre and post processors during identity collections to address common use cases. If you are not familiar with data processors, I recommend reading the Data Processors Basics before proceeding, as it will provide a foundational understanding for the concepts discussed in this blog.","date":"2024-01-31T00:00:00.000Z","tags":[{"inline":true,"label":"Data Processors","permalink":"/RSA/basics/tags/data-processors"},{"inline":true,"label":"Identities","permalink":"/RSA/basics/tags/identities"}],"readingTime":20.333333333333332,"hasTruncateMarker":true,"authors":[{"name":"Pradeep Kadambar","title":"Creator","url":"https://www.linkedin.com/in/pradeepkg/","imageURL":"https://github.com/pradeepkg.png","key":"pradeepkg","page":null}],"frontMatter":{"slug":"data-processors-idc","title":"Manipulating Identities","date":"2024-01-31T00:00:00.000Z","authors":"pradeepkg","tags":["Data Processors","Identities"],"keywords":["Data Processors","Identities"]},"unlisted":false,"prevItem":{"title":"Manipulating Accounts","permalink":"/RSA/basics/data-processors-adc"},"nextItem":{"title":"Data Processor Basics","permalink":"/RSA/basics/data-processors-basics"}},"content":"import Admonition from \\"@theme/Admonition\\";\\r\\n\\r\\nIn this blog post, I will guide you through the effective utilization of pre and post processors during identity collections to address common use cases. If you are not familiar with data processors, I recommend reading the **[Data Processors Basics](data-processors-basics)** before proceeding, as it will provide a foundational understanding for the concepts discussed in this blog.\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\n### Enabling Data Processors\\r\\n\\r\\nData processing is an advanced feature that requires explicit activation by the System Administrator. To enable this feature, follow the steps outlined below:\\r\\n\\r\\n1. Login to console as System Administrator\\r\\n2. Navigate to Admin > System.\\r\\n3. Click on Edit\\r\\n4. Under Custom, add enableCustomPostProcessingScript with value true\\r\\n5. Click Save\\r\\n6. Click OK.\\r\\n\\r\\n### Set termination status based on Active Directory accountExpires value\\r\\n\\r\\nIn this specific use case, our goal is to gather user identities from Active Directory, including the _accountExpires_ attribute, which indicates the expiration date of an account. Upon collecting this identity information in G&L, our objective is to label the identity as terminated if the _accountExpires_ value is greater than or equal to the current date.\\r\\n\\r\\nTo achieve this, we can leverage the _Pre_ID_Unification_Handler_. This handler allows us to manipulate the raw data collected from Active Directory before the unification process takes place. By incorporating logic within this handler, we can effectively set the termination status based on the comparison between the _accountExpires_ value and the current date. This ensures that the identity management system appropriately identifies and marks accounts as terminated in accordance with the specified criteria.\\r\\n\\r\\n1. Login to console as System Administrator\\r\\n2. Navigate to **Unification Config** and click on **Pre Process Script**\\r\\n3. Update to add the following SQL block below the comment \\"Custom Code Goes Here\\". Here, we are setting the terminated flag based on the custom date attribute that contains the _accountExpires_ value from Active Directory IDC.\\r\\n\\r\\n```sql showLineNumbers\\r\\nUPDATE\\r\\n  T_RAW_USER\\r\\nSET\\r\\n  IS_TERMINATED = 1\\r\\nWHERE\\r\\n  CUS_ATTR_USER_CAD_1 <= SYSDATE\\r\\n  and run_id =(\\r\\n    select\\r\\n      MAX(v_run_id)\\r\\n    from\\r\\n      t_raw_user\\r\\n    where\\r\\n      idc_id = <<YOUR_IDC_ID>>\\r\\n  );\\r\\n```\\r\\n\\r\\n4. Click **Validate** to check for syntactical errors.\\r\\n5. Click **Save**\\r\\n\\r\\n### Generate User Name\\r\\n\\r\\nIn scenarios where G&L is tasked with onboarding user accounts across multiple systems, the need for generating a unique user ID becomes crucial. While straightforward cases can be addressed through Naming Policies, more intricate situations may demand customized solutions.\\r\\n\\r\\nTo tackle these complexities, we can employ the _Post_ID_Unification_Handler_. This handler allows us to manipulate the unified data after the unification process has taken place. By incorporating custom logic within this handler, we can address the nuanced requirements of generating unique user IDs, ensuring that the system adapts to diverse scenarios during the onboarding process. This approach provides a flexible and tailored solution for managing user account onboarding in a variety of system environments.\\r\\n\\r\\n1. Login to console as System Administrator\\r\\n2. Navigate to **Unification Config** and click on **Post Process Script**\\r\\n3. Update to add the following SQL block below the comment \\"Custom Code Goes Here\\". Here we are setting the generated _sAMAccountName_ name in the custom user attribute post unification.\\r\\n\\r\\n```sql showLineNumbers\\r\\nFOR NewUser IN (\\r\\n  SELECT\\r\\n    userID,\\r\\n    sAMAccountName\\r\\n  FROM\\r\\n    (\\r\\n      SELECT\\r\\n        USER_ID as userID,\\r\\n        UPPER(\\r\\n          SUBSTR(U.FIRST_NAME, 1, 1) || SUBSTR(U.LAST_NAME, 1, 5)\\r\\n        ) AS sAMAccountName\\r\\n      FROM\\r\\n        T_MASTER_ENTERPRISE_USERS U\\r\\n      WHERE\\r\\n        /* sAMAccountName */\\r\\n        U.CUS_ATTR_USER_CAS_3 IS NULL\\r\\n        AND U.UNIQUE_ID IS NULL\\r\\n        AND U.USER_ID <> \'AveksaAdmin\'\\r\\n        AND TO_DATE(U.CREATION_DATE, \'DD-MON-YY\') = TO_DATE(SYSDATE, \'DD-MON-YY\')\\r\\n        AND U.DELETION_DATE IS NULL\\r\\n    )\\r\\n) LOOP\\r\\n/* Update the custom user attribute sAMAccountName that holds generated sAMAccountName */\\r\\nUPDATE\\r\\n  T_MASTER_ENTERPRISE_USERS U\\r\\nSET\\r\\n  U.CUS_ATTR_USER_CAS_3 = NewUser.sAMAccountName\\r\\nWHERE\\r\\n  U.USER_ID = NewUser.userID;\\r\\nCOMMIT;\\r\\nEND LOOP;\\r\\n```\\r\\n\\r\\n4. Click **Validate** to check for syntactical errors.\\r\\n5. Click **Save**"},{"id":"data-processors-basics","metadata":{"permalink":"/RSA/basics/data-processors-basics","source":"@site/basics/data-processors/data-processors-basics/data-processors-basics.mdx","title":"Data Processor Basics","description":"Data processors have been integral in RSA Governance and Lifecycle (G&L) systems, playing a crucial role in manipulating data throughout different stages of collections, unification or Separation of Duties (SoD) processing. Traditionally, the integration of custom logic into these data processors required direct system access to the AVDB database and the use of tools such as SQL Developer. However, with the evolution of G&L products, there has been a paradigm shift in the approach to implementing custom logic within data processors.","date":"2024-01-30T00:00:00.000Z","tags":[{"inline":true,"label":"Data Processors","permalink":"/RSA/basics/tags/data-processors"}],"readingTime":19.033333333333335,"hasTruncateMarker":true,"authors":[{"name":"Pradeep Kadambar","title":"Creator","url":"https://www.linkedin.com/in/pradeepkg/","imageURL":"https://github.com/pradeepkg.png","key":"pradeepkg","page":null}],"frontMatter":{"slug":"data-processors-basics","title":"Data Processor Basics","date":"2024-01-30T00:00:00.000Z","authors":"pradeepkg","tags":["Data Processors"],"keywords":["Data Processors"]},"unlisted":false,"prevItem":{"title":"Manipulating Identities","permalink":"/RSA/basics/data-processors-idc"},"nextItem":{"title":"REST Collector Authentication","permalink":"/RSA/basics/rest-collector-authentication"}},"content":"import Admonition from \\"@theme/Admonition\\";\\r\\n\\r\\nData processors have been integral in **RSA Governance and Lifecycle (G&L)** systems, playing a crucial role in manipulating data throughout different stages of collections, unification or Separation of Duties (SoD) processing. Traditionally, the integration of custom logic into these data processors required direct system access to the AVDB database and the use of tools such as SQL Developer. However, with the evolution of G&L products, there has been a paradigm shift in the approach to implementing custom logic within data processors. \\r\\n\\r\\nIn this blog post, we\'ll explore the historical context of data processors and examine contemporary solutions that not only streamline the customization process but also eliminate the necessity for direct database access. This evolution promises a more accessible and agile approach for developers working with G&L systems.\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\n### Pre 7.5.2: Common Extension Points\\r\\n\\r\\nIn versions preceding 7.5.2, customization within Governance and Lifecycle (G&L) systems was facilitated through various extension points. These extension points served as key areas where developers could inject custom logic to tailor the system according to specific organizational needs. Below is a table outlining some of the common extension points utilized in G&L systems before version 7.5.2:\\r\\n| Processor Name | Description |\\r\\n| ---- | ---- |\\r\\n| **Pre_ID_Unification_Handler** | Any action needed post identity data collection but before unification. Mostly used to manipulate the T_DC_SOURCEDATA_USER table |\\r\\n| **Post_ID_Unification_Handler** | Any action that needs to be performed after the identities have been collected, unified and persisted in the system |\\r\\n| **Pre_Supervisor_Resolution** | Any action that needs to be performed after the identities have been collected, but before supervisor references are resolved |\\r\\n| **Pre_ADC_Handler** | Any action to be performed post account data collection but before processing. |\\r\\n| **Post_Account_Data_Load_Handler** | Action to be taken once account data has been collected and persisted in the system |\\r\\n| **Post_MAEDC_Load_Handler** | Any action needed post multi-app EDC run |\\r\\n| **Post_Process_SoD_Violations** | Actions to be taken post SoD rules have been evaluated and violations generated |\\r\\n\\r\\n### G&L Cloud and 7.5.2 On-Premise: Easy Customization\\r\\n\\r\\nIn the newest G&L Cloud and on-premise versions 7.5.2 and above, RSA has made customizing your system a breeze. This significant enhancement simplifies the process of adding and maintaining custom extensions, making it more intuitive and user-friendly for developers and administrators alike.\\r\\n\\r\\nTo enable usage of processors, the following system settings must be set.\\r\\n\\r\\n```\\r\\ncustom.enableCustomPostProcessingScript = true\\r\\n```\\r\\n\\r\\nAfter activation, you\'ll find the \\"Pre Custom Processing\\" and \\"Post Custom Processing\\" options available in designated configuration areas.\\r\\n\\r\\n| Process/Collector Name            | Description                                                                                                           |\\r\\n| --------------------------------- | --------------------------------------------------------------------------------------------------------------------- |\\r\\n| **Identity Collectors**           | Any action needed before or after identity data collection but before unification.                                    |\\r\\n| **Unification**                   | Any action that needs to be performed before or after identity unification (Pre Process Script / Post Process Script) |\\r\\n| **Account Collectors (ADC)**      | Any action to be performed before or after account data collection.                                                   |\\r\\n| **Entitlements Collectors (EDC)** | Any action to be performed before or after entitlements data collection.                                              |\\r\\n| **Role Collectors (RDC)**         | Any action to be performed before or after role data collection.                                                      |\\r\\n| **Multi-App Collectors**          | Similar to ADC / EDC / RDC                                                                                            |\\r\\n| **Data Access Collectors**        | NA                                                                                                                    |\\r\\n| **App Metadata Collectors**       | NA                                                                                                                    |\\r\\n\\r\\n<Admonition type=\\"warning\\" title=\\"Caution\\">\\r\\n  These data processors are advanced product features and should be utilized\\r\\n  with caution and discretion.\\r\\n</Admonition>"},{"id":"rest-collector-authentication","metadata":{"permalink":"/RSA/basics/rest-collector-authentication","source":"@site/basics/rest-collector-authentication/auth.mdx","title":"REST Collector Authentication","description":"In recent blog posts, we\'ve explored numerous integrations between RSA G&L and various SaaS applications, primarily relying on the Generic REST collectors. Despite their flexibility, navigating through the intricate components of these collectors can be overwhelming. This article aims to simplify the process by focusing on the authentication aspect, providing an overview of the supported authentication methods and offering common examples to clarify the integration process.","date":"2023-10-25T00:00:00.000Z","tags":[{"inline":true,"label":"Collections","permalink":"/RSA/basics/tags/collections"},{"inline":true,"label":"REST","permalink":"/RSA/basics/tags/rest"},{"inline":true,"label":"Authentication","permalink":"/RSA/basics/tags/authentication"},{"inline":true,"label":"Basic","permalink":"/RSA/basics/tags/basic"},{"inline":true,"label":"Token","permalink":"/RSA/basics/tags/token"},{"inline":true,"label":"OAuth","permalink":"/RSA/basics/tags/o-auth"}],"readingTime":21.733333333333334,"hasTruncateMarker":true,"authors":[{"name":"Pradeep Kadambar","title":"Creator","url":"https://www.linkedin.com/in/pradeepkg/","imageURL":"https://github.com/pradeepkg.png","key":"pradeepkg","page":null}],"frontMatter":{"slug":"rest-collector-authentication","title":"REST Collector Authentication","date":"2023-10-25T00:00:00.000Z","authors":"pradeepkg","tags":["Collections","REST","Authentication","Basic","Token","OAuth"],"keywords":["Collections","REST","Authentication","Basic","Token","OAuth"]},"unlisted":false,"prevItem":{"title":"Data Processor Basics","permalink":"/RSA/basics/data-processors-basics"}},"content":"import Admonition from \\"@theme/Admonition\\";\\r\\n\\r\\nIn recent blog posts, we\'ve explored numerous integrations between RSA G&L and various SaaS applications, primarily relying on the Generic REST collectors. Despite their flexibility, navigating through the intricate components of these collectors can be overwhelming. This article aims to simplify the process by focusing on the authentication aspect, providing an overview of the supported authentication methods and offering common examples to clarify the integration process.\\r\\n\\r\\nAs of v8.0, RSA G&L generic REST collector supports `Basic`, `Token` and `OAuth2` authentication methods. Rest of the article will cover the details of each configuration with examples.\\r\\n\x3c!-- truncate --\x3e\\r\\n\\r\\n### Basic\\r\\nThis authentication type is an implementation of the HTTP Basic Authentication Scheme. This authentication type requires that the user name and password values are provided in the collector configuration and during the API invocation transmits the Base64 encoded pair of user name and password. \\r\\n<Admonition type=\\"info\\">\\r\\nThe G&L collector framework will ensure the `Authorization` headers are set on the request and no additional configuration  are required in the API page.\\r\\n</Admonition>\\r\\n\\r\\n![img](img/basic-1.png)\\r\\n\\r\\n<table>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">1</span></td>\\r\\n    <td><span class=\\"header-2-text\\">User Authentication Type</span></td>\\r\\n    <td>Basic</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">2</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Username</span></td>\\r\\n    <td>The service account user name</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">3</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Password</span></td>\\r\\n    <td>The password corresponding to the user name</td>\\r\\n  </tr>\\r\\n</table>\\r\\n\\r\\nThe API configuration page will look something like this without needing any explicit `Authorization` headers.<br />![img](img/basic-2.png)\\r\\n\\r\\n**Examples**\\r\\n- [Freshservice](./../blog/freshservice)\\r\\n- [Zendesk](./../blog/zendesk)\\r\\n\\r\\n\ud83d\udcd3 **References**\\r\\n- [Mozilla : Basic Authentication](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization#basic_authentication)\\r\\n- [RFC - The \'Basic\' HTTP Authentication Scheme](https://datatracker.ietf.org/doc/html/rfc7617)\\r\\n\\r\\n### Token\\r\\nThis authentication type is an implementation of the HTTP Bearer Authentication Scheme. This authentication type requires that a valid token value is provided in the collector configuration. The generic REST collector support both static as well as dynamic token types.\\r\\n\\r\\nOnce the connection details for the token has been configured, the subsequently all API calls must include the `Authorization` HTTP header with value `Bearer ${AuthenticationToken}`.\\r\\n\\r\\n\ud83d\udcd3 **References**\\r\\n- [Mozilla : HTTP authentication](https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication)\\r\\n- [RFC - The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://datatracker.ietf.org/doc/html/rfc6750)\\r\\n\\r\\n#### Static Token\\r\\n![img](img/token-static-1.png)\\r\\n\\r\\n<table>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">1</span></td>\\r\\n    <td><span class=\\"header-2-text\\">User Authentication Type</span></td>\\r\\n    <td>Token</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">2</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Get Token from URL</span></td>\\r\\n    <td>Unchecked</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">3</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Authentication Token</span></td>\\r\\n    <td>Static token value</td>\\r\\n  </tr>\\r\\n</table>\\r\\n\\r\\n#### Examples\\r\\n- [Sentry](./../blog/sentry)\\r\\n\\r\\n#### Dynamic Token\\r\\nThe configuration for getting a dynamic token can vary from endpoint to endpoint. Generally the token URL accepts requests over **POST** with additional authentication requirements passed through the POST body. The collector does support dynamic token calls over **GET** if needed.\\r\\n\\r\\n#### Examples\\r\\n- [PingOne](./../blog/pingone)\\r\\n- [Dynatrace](./../blog/dynatrace)\\r\\n\\r\\n### OAuth2\\r\\nThis authentication type supports the OAuth 2 authorization flow. \\r\\n\\r\\n![img](img/oauth-1.png)\\r\\n\\r\\n<table>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">1</span></td>\\r\\n    <td><span class=\\"header-2-text\\">User Authentication Type</span></td>\\r\\n    <td>OAuth2</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">2</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Client ID</span></td>\\r\\n    <td>The `client_id` for the OAuth application created on the target for the integration</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">3</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Client Secret</span></td>\\r\\n    <td>The `client_secret` corresponding to the `client_id`</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">4</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Authentication URL</span></td>\\r\\n    <td>Authentication URL to retrieve an authorization `code` and an optional `refresh_token` from target application</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">5</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Access Token URL</span></td>\\r\\n    <td>Access token URL to acquire an access token using the authorization `code` from the target application</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">6</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Scope</span></td>\\r\\n    <td>`scope` for the `access_token` being requested</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">7</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Access Token Expiry</span></td>\\r\\n    <td>`access_token` expiration period in milliseconds. This value will be updated if the `expires_in` parameter is available in token responses. If `refresh_token` was provided in the access token response, G&L will make a access token request when the current token expires.</td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td><span class=\\"header-2-text\\">8</span></td>\\r\\n    <td><span class=\\"header-2-text\\">Token Validity</span></td>\\r\\n    <td>Displays when the current `access_token` will expire</td>\\r\\n  </tr>\\r\\n</table>\\r\\n\\r\\nOnce the above configurations are set, click on ***Get OAuth 2.0 Access Token*** to send the authorization request. Depending on the target application, you may have to go through the authentication process and once completed will return the `code`, `refresh_token`, `access_token` to  https://instance.securid.com/aveksa/oauth/callback\\r\\n\\r\\n#### Examples\\r\\n- [DocuSign](./../blog/docusign)\\r\\n- [Asana](./../blog/asana)\\r\\n- [Google Workspace](./../blog/google-workspace)\\r\\n\\r\\n\ud83d\udcd3 **References**\\r\\n- [OAuth 2.0](https://oauth.net/2/)"}]}}')}}]);